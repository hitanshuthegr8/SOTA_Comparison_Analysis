# ğŸ“ Project Structure

```
research-pipeline/
â”‚
â”œâ”€â”€ ğŸ“„ app.py                    # Main Flask application (ALL CODE IN ONE FILE)
â”‚   â”œâ”€â”€ Data Structures
â”‚   â”‚   â”œâ”€â”€ ParsedPaper
â”‚   â”‚   â”œâ”€â”€ PaperWeaknesses
â”‚   â”‚   â”œâ”€â”€ WeaknessAnalysis
â”‚   â”‚   â””â”€â”€ ProposedMethod
â”‚   â”‚
â”‚   â”œâ”€â”€ Core Components
â”‚   â”‚   â”œâ”€â”€ GroqClient              # API communication
â”‚   â”‚   â”œâ”€â”€ PaperParser             # STEP 1: PDF â†’ Structured JSON
â”‚   â”‚   â”œâ”€â”€ WeaknessExtractor       # STEP 2: Extract weaknesses
â”‚   â”‚   â”œâ”€â”€ WeaknessNormalizer      # STEP 3: Canonicalize weaknesses
â”‚   â”‚   â”œâ”€â”€ WeaknessFusion          # STEP 4: Analyze patterns
â”‚   â”‚   â”œâ”€â”€ MethodSynthesizer       # STEP 5: Generate new method
â”‚   â”‚   â””â”€â”€ ComparativeAnalyzer     # STEP 6-7: Compare & table
â”‚   â”‚
â”‚   â”œâ”€â”€ Pipeline Orchestrator
â”‚   â”‚   â””â”€â”€ ResearchPipeline        # Coordinates all steps
â”‚   â”‚
â”‚   â””â”€â”€ Flask Routes
â”‚       â”œâ”€â”€ / (GET)                 # Web interface
â”‚       â”œâ”€â”€ /analyze (POST)         # Main analysis endpoint
â”‚       â””â”€â”€ /health (GET)           # Health check
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt          # Python dependencies
â”‚   â”œâ”€â”€ Flask==3.0.0
â”‚   â”œâ”€â”€ requests==2.31.0
â”‚   â”œâ”€â”€ PyPDF2==3.0.1
â”‚   â”œâ”€â”€ Werkzeug==3.0.1
â”‚   â””â”€â”€ python-dotenv==1.0.0
â”‚
â”œâ”€â”€ ğŸ“„ .env.example              # Environment variables template
â”‚   â””â”€â”€ GROQ_API_KEY=your_key_here
â”‚
â”œâ”€â”€ ğŸ“„ README.md                 # Full documentation
â”‚
â”œâ”€â”€ ğŸ“„ PROJECT_STRUCTURE.md      # This file
â”‚
â”œâ”€â”€ ğŸ“„ test_setup.py             # Setup verification script
â”‚   â”œâ”€â”€ test_imports()
â”‚   â”œâ”€â”€ test_api_key()
â”‚   â”œâ”€â”€ test_groq_connection()
â”‚   â””â”€â”€ test_file_structure()
â”‚
â”œâ”€â”€ ğŸ“„ run.sh                    # Quick start script (Linux/Mac)
â”‚
â””â”€â”€ ğŸ“„ .gitignore                # Git ignore rules

```

## ğŸ”„ Data Flow

```
Upload PDFs
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ResearchPipeline                      â”‚
â”‚                                                          â”‚
â”‚  1. PaperParser                                         â”‚
â”‚     Input: PDF files                                     â”‚
â”‚     Output: ParsedPaper (title, abstract, method, etc)  â”‚
â”‚                                                          â”‚
â”‚  2. WeaknessExtractor                                   â”‚
â”‚     Input: ParsedPaper                                   â”‚
â”‚     Output: PaperWeaknesses (list of weaknesses)        â”‚
â”‚                                                          â”‚
â”‚  3. WeaknessNormalizer                                  â”‚
â”‚     Input: Raw weaknesses                               â”‚
â”‚     Output: Canonical weaknesses                        â”‚
â”‚                                                          â”‚
â”‚  4. WeaknessFusion                                      â”‚
â”‚     Input: Weaknesses from both papers                  â”‚
â”‚     Output: WeaknessAnalysis (shared, unique)           â”‚
â”‚                                                          â”‚
â”‚  5. MethodSynthesizer                                   â”‚
â”‚     Input: WeaknessAnalysis                             â”‚
â”‚     Output: ProposedMethod (name, idea, components)     â”‚
â”‚                                                          â”‚
â”‚  6. ComparativeAnalyzer                                 â”‚
â”‚     Input: Papers + Weaknesses + ProposedMethod         â”‚
â”‚     Output: Comparison table                            â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Display Results
```

## ğŸ¯ Key Classes

### 1. **GroqClient**
- Handles all API communication
- Single method: `chat_completion(messages, temperature, max_tokens)`
- Error handling and retries

### 2. **PaperParser**
- Extracts structured sections from PDFs
- Uses LLM to identify: title, abstract, method, experiments, limitations
- Returns: `ParsedPaper` dataclass

### 3. **WeaknessExtractor**
- Section-wise analysis (method, experiments, limitations)
- Strict reviewer mode prompting
- Returns: `PaperWeaknesses` with list of issues

### 4. **WeaknessNormalizer**
- Groups similar weaknesses
- Merges duplicates
- Creates canonical research-style labels

### 5. **WeaknessFusion**
- Identifies shared weaknesses
- Separates unique weaknesses per paper
- Returns: `WeaknessAnalysis` dataclass

### 6. **MethodSynthesizer**
- Switches LLM from reviewer â†’ author mode
- Generates novel method addressing weaknesses
- Returns: `ProposedMethod` with components

### 7. **ComparativeAnalyzer**
- Multi-aspect comparison
- Fixed schema for consistency
- Returns: Comparison table dict

### 8. **ResearchPipeline**
- Orchestrates entire workflow
- Manages data flow between components
- Single entry point: `process(pdf_a, pdf_b)`

## ğŸŒ API Endpoints

### `GET /`
- Serves HTML interface
- Embedded CSS and JavaScript
- File upload form
- Results display area

### `POST /analyze`
- Accepts: `multipart/form-data` with two PDF files
- Validates: File presence and API key
- Processes: Runs complete pipeline
- Returns: JSON with all results

### `GET /health`
- Health check
- Returns: Server status and API configuration

## ğŸ“Š Data Structures

### ParsedPaper
```python
{
    "paper_id": "A" | "B",
    "title": str | null,
    "abstract": str | null,
    "method": str | null,
    "experiments": str | null,
    "limitations": str | null
}
```

### PaperWeaknesses
```python
{
    "paper_id": "A" | "B",
    "weaknesses": [str, ...]
}
```

### WeaknessAnalysis
```python
{
    "shared": [str, ...],
    "paper_a_only": [str, ...],
    "paper_b_only": [str, ...]
}
```

### ProposedMethod
```python
{
    "method_name": str,
    "core_idea": str,
    "components": [str, ...],
    "addresses_weaknesses": str
}
```

### Comparison Table
```python
{
    "Task scalability": {
        "paper_a": str,
        "paper_b": str,
        "proposed": str
    },
    "Theoretical grounding": { ... },
    "Memory efficiency": { ... },
    "Generalization capability": { ... }
}
```

## ğŸ”§ Configuration

### Environment Variables
- `GROQ_API_KEY` - Required for API access
- `FLASK_DEBUG` - Optional, defaults to True in dev

### Model Configuration
- Model: `llama-3.3-70b-versatile`
- Temperature: 0.1-0.5 (varies by step)
- Max tokens: 800-3000 (varies by step)

## ğŸš€ Execution Flow

1. **User uploads** two PDFs via web interface
2. **Flask receives** POST request at `/analyze`
3. **Files saved** to temporary directory
4. **Pipeline created** with Groq API client
5. **Process runs** through all 6 steps
6. **Results returned** as JSON
7. **JavaScript renders** results in UI
8. **Temp files cleaned** up

## ğŸ’¾ Storage

- **Temporary**: Uses system temp directory
- **Uploads**: Saved only during processing
- **Cleanup**: Automatic after each request
- **No persistence**: Stateless design

## ğŸ¨ Frontend

- **Single-page app**: All HTML/CSS/JS embedded
- **No build step**: Pure vanilla JavaScript
- **Responsive**: Works on mobile and desktop
- **Real-time updates**: Loading states and progress

## ğŸ”’ Security

- **File size limits**: 50MB max
- **File type validation**: PDF/TXT only
- **Secure filenames**: Using Werkzeug
- **Temp directory**: Isolated per request
- **No file retention**: Immediate cleanup

---

**Total Lines of Code: ~1,000 lines in single file**
**Dependencies: 5 packages**
**Complexity: Production-ready research tool**
